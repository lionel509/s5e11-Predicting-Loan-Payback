{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0477ce0",
   "metadata": {},
   "source": [
    "# Advanced Loan Payback Prediction — Optimized Beyond 92%\n",
    "\n",
    "This notebook pushes the model past a 92% accuracy baseline using a modern, reproducible pipeline:\n",
    "- Robust CV and leak-safe OOF predictions\n",
    "- Ultra-advanced feature engineering and selection\n",
    "- Optuna hyperparameter optimization for tree boosters\n",
    "- Adversarial validation, pseudo-labeling, multi-level stacking (tree-based models)\n",
    "- Probability calibration and threshold optimization\n",
    "\n",
    "Notes\n",
    "- Heavy steps are optional-guarded and can be toggled with flags.\n",
    "- The notebook installs missing packages on-the-fly when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1751be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:57:51] Notebook started\n",
      "Root: /Users/lionelweng/Downloads/s5e11-Predicting-Loan-Payback\n",
      "Python: 3.13.5  |  Seed: 42\n"
     ]
    }
   ],
   "source": [
    "# 1) Environment Setup and Configuration\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Reproducibility\n",
    "import numpy as np\n",
    "import random\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Project paths\n",
    "ROOT = Path.cwd()\n",
    "DATA_DIR = ROOT / 'Data'\n",
    "SPLITS_DIR = DATA_DIR / 'splits'\n",
    "SUB_DIR = ROOT / 'submissions'\n",
    "MODELS_DIR = ROOT / 'models'\n",
    "SUB_DIR.mkdir(exist_ok=True)\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Lightweight logger\n",
    "start_ts = time.time()\n",
    "def log(msg):\n",
    "    ts = time.strftime('%H:%M:%S')\n",
    "    print(f\"[{ts}] {msg}\")\n",
    "\n",
    "log(\"Notebook started\")\n",
    "print(f\"Root: {ROOT}\")\n",
    "print(f\"Python: {sys.version.split()[0]}  |  Seed: {SEED}\")\n",
    "\n",
    "# On-demand installer for optional packages\n",
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "def ensure(pkg, import_name=None, version_spec=None):\n",
    "    name = import_name or pkg\n",
    "    try:\n",
    "        return importlib.import_module(name)\n",
    "    except ImportError:\n",
    "        cmd = [sys.executable, '-m', 'pip', 'install', pkg + (version_spec or '')]\n",
    "        log(f\"Installing {pkg}{version_spec or ''} ...\")\n",
    "        subprocess.run(cmd, check=True)\n",
    "        return importlib.import_module(name)\n",
    "\n",
    "# Core libs (already in requirements)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score, precision_score,\n",
    "                             recall_score, confusion_matrix, classification_report,\n",
    "                             roc_curve, precision_recall_curve)\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "                              ExtraTreesClassifier, HistGradientBoostingClassifier)\n",
    "from joblib import dump\n",
    "\n",
    "# Fast boot options: defer heavy imports to later cells; background warm-up is disabled by default\n",
    "FAST_BOOT = True\n",
    "BACKGROUND_WARMUP = False  # set to True if you want background warm-up on capable machines\n",
    "\n",
    "# Background warm-up of heavy libraries (non-blocking)\n",
    "from threading import Thread\n",
    "WARMUP_STATUS = {'started': False, 'done': False, 'logs': []}\n",
    "\n",
    "def _bg_log(msg):\n",
    "    ts = time.strftime('%H:%M:%S')\n",
    "    print(f\"[{ts}] [warmup] {msg}\")\n",
    "    WARMUP_STATUS['logs'].append(msg)\n",
    "\n",
    "def _background_imports():\n",
    "    WARMUP_STATUS['started'] = True\n",
    "    libs = [\n",
    "        ('optuna', 'optuna'),\n",
    "        ('xgboost', 'xgboost'),\n",
    "        ('lightgbm', 'lightgbm'),\n",
    "        ('catboost', 'catboost'),\n",
    "    ]\n",
    "    for pkg, name in libs:\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            ensure(pkg, name)\n",
    "            _bg_log(f\"import {name}: {time.time() - t0:.1f}s\")\n",
    "        except Exception as e:\n",
    "            _bg_log(f\"skip {name}: {e}\")\n",
    "    WARMUP_STATUS['done'] = True\n",
    "    _bg_log('warm-up complete')\n",
    "\n",
    "if BACKGROUND_WARMUP:\n",
    "    Thread(target=_background_imports, daemon=True).start()\n",
    "    log('Background warm-up started (heavy imports running asynchronously)')\n",
    "\n",
    "# Note: Heavy libs like optuna/xgboost/lightgbm/catboost will be imported\n",
    "# on-demand in later cells to keep this cell fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbc8401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG 20:57:53] Debugging enabled\n"
     ]
    }
   ],
   "source": [
    "# === Debug configuration & helpers ===\n",
    "DEBUG = True  # toggle to False to silence debug traces\n",
    "\n",
    "# Local imports to make this cell runnable standalone\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def log_debug(msg):\n",
    "    if DEBUG:\n",
    "        ts = time.strftime('%H:%M:%S')\n",
    "        print(f\"[DEBUG {ts}] {msg}\")\n",
    "\n",
    "def trace_df(df, name, head=3):\n",
    "    if not DEBUG:\n",
    "        return\n",
    "    print(f\"\\n[DEBUG] {name}: shape={df.shape}\")\n",
    "    print(df.head(head))\n",
    "    nulls = df.isnull().mean().sort_values(ascending=False)[:10]\n",
    "    print(\"[DEBUG] top-10 null ratios:\\n\", nulls)\n",
    "\n",
    "def trace_array(arr, name):\n",
    "    if not DEBUG:\n",
    "        return\n",
    "    arr = np.asarray(arr)\n",
    "    print(f\"[DEBUG] {name}: shape={arr.shape} | min={arr.min():.4f} max={arr.max():.4f} mean={arr.mean():.4f}\")\n",
    "\n",
    "# Make Optuna more chatty when DEBUG\n",
    "try:\n",
    "    import optuna\n",
    "    if DEBUG:\n",
    "        optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "except Exception as _e:\n",
    "    pass\n",
    "\n",
    "log_debug(\"Debugging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6fe53",
   "metadata": {},
   "source": [
    "## 2) Advanced Data Loading and Profiling\n",
    "We load train/test from `Data/`. If `Data/splits/train_split.csv` and `Data/splits/test_split.csv` exist, we use them as a leak-free validation split. We auto-detect the target as the column in train that is not present in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc09d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:57:53] Using precomputed splits from Data/splits\n",
      "[20:57:54] Detected target: loan_paid_back | id: id\n",
      "\n",
      "=== Train (475195 rows, 13 columns) ===\n",
      "Head:\n",
      "        id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  100143       92432.16                 0.067           636     14369.05   \n",
      "1  560097       28850.38                 0.122           643      8471.26   \n",
      "2  356847       39427.43                 0.041           672      7647.50   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          13.78    Male        Married      Bachelor's          Employed   \n",
      "1          14.40  Female        Married     High School          Employed   \n",
      "2          11.99    Male        Married     High School          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  loan_paid_back  \n",
      "0  Debt consolidation             D1             1.0  \n",
      "1  Debt consolidation             D5             1.0  \n",
      "2  Debt consolidation             C3             1.0  \n",
      "Nulls:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "Dtypes:\n",
      " object     6\n",
      "float64    5\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Validation (118799 rows, 13 columns) ===\n",
      "Head:\n",
      "        id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  523771       28114.66                 0.080           690      7133.85   \n",
      "1  524810      122933.72                 0.046           659      7268.12   \n",
      "2  100141       26379.82                 0.140           710      9386.27   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          11.80  Female        Married     High School          Employed   \n",
      "1           7.46    Male         Single     High School          Employed   \n",
      "2          12.73    Male        Married      Bachelor's          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  loan_paid_back  \n",
      "0                 Car             C1             1.0  \n",
      "1                Home             D5             1.0  \n",
      "2  Debt consolidation             C2             1.0  \n",
      "Nulls:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "Dtypes:\n",
      " object     6\n",
      "float64    5\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Test (254569 rows, 12 columns) ===\n",
      "Head:\n",
      "        id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  593994       28781.05                 0.049           626     11461.42   \n",
      "1  593995       46626.39                 0.093           732     15492.25   \n",
      "2  593996       54954.89                 0.367           611      3796.41   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          14.73  Female         Single     High School          Employed   \n",
      "1          12.85  Female        Married        Master's          Employed   \n",
      "2          13.29    Male         Single      Bachelor's          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  \n",
      "0               Other             D5  \n",
      "1               Other             C1  \n",
      "2  Debt consolidation             D1  \n",
      "Nulls:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "Dtypes:\n",
      " object     6\n",
      "float64    4\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class balance (train):\n",
      "loan_paid_back\n",
      "1.0    0.798819\n",
      "0.0    0.201181\n",
      "Name: share, dtype: float64\n",
      "[20:57:54] Numeric: 6 | Categorical: 6\n",
      "[20:57:54] Detected target: loan_paid_back | id: id\n",
      "\n",
      "=== Train (475195 rows, 13 columns) ===\n",
      "Head:\n",
      "        id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  100143       92432.16                 0.067           636     14369.05   \n",
      "1  560097       28850.38                 0.122           643      8471.26   \n",
      "2  356847       39427.43                 0.041           672      7647.50   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          13.78    Male        Married      Bachelor's          Employed   \n",
      "1          14.40  Female        Married     High School          Employed   \n",
      "2          11.99    Male        Married     High School          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  loan_paid_back  \n",
      "0  Debt consolidation             D1             1.0  \n",
      "1  Debt consolidation             D5             1.0  \n",
      "2  Debt consolidation             C3             1.0  \n",
      "Nulls:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "Dtypes:\n",
      " object     6\n",
      "float64    5\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Validation (118799 rows, 13 columns) ===\n",
      "Head:\n",
      "        id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  523771       28114.66                 0.080           690      7133.85   \n",
      "1  524810      122933.72                 0.046           659      7268.12   \n",
      "2  100141       26379.82                 0.140           710      9386.27   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          11.80  Female        Married     High School          Employed   \n",
      "1           7.46    Male         Single     High School          Employed   \n",
      "2          12.73    Male        Married      Bachelor's          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  loan_paid_back  \n",
      "0                 Car             C1             1.0  \n",
      "1                Home             D5             1.0  \n",
      "2  Debt consolidation             C2             1.0  \n",
      "Nulls:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "Dtypes:\n",
      " object     6\n",
      "float64    5\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Test (254569 rows, 12 columns) ===\n",
      "Head:\n",
      "        id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  593994       28781.05                 0.049           626     11461.42   \n",
      "1  593995       46626.39                 0.093           732     15492.25   \n",
      "2  593996       54954.89                 0.367           611      3796.41   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          14.73  Female         Single     High School          Employed   \n",
      "1          12.85  Female        Married        Master's          Employed   \n",
      "2          13.29    Male         Single      Bachelor's          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  \n",
      "0               Other             D5  \n",
      "1               Other             C1  \n",
      "2  Debt consolidation             D1  \n",
      "Nulls:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "Dtypes:\n",
      " object     6\n",
      "float64    4\n",
      "int64      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class balance (train):\n",
      "loan_paid_back\n",
      "1.0    0.798819\n",
      "0.0    0.201181\n",
      "Name: share, dtype: float64\n",
      "[20:57:54] Numeric: 6 | Categorical: 6\n"
     ]
    }
   ],
   "source": [
    "# Load datasets and construct a validation split\n",
    "\n",
    "def detect_target(train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
    "    diff = list(set(train_df.columns) - set(test_df.columns))\n",
    "    # Prefer a binary label\n",
    "    candidates = []\n",
    "    for c in diff:\n",
    "        if train_df[c].nunique() <= 3:\n",
    "            candidates.append(c)\n",
    "    if len(candidates) == 1:\n",
    "        return candidates[0]\n",
    "    if len(diff) == 1:\n",
    "        return diff[0]\n",
    "    # Common fallbacks\n",
    "    for name in ['loan_paid_back', 'target', 'label', 'is_default', 'default', 'paid']:\n",
    "        if name in train_df.columns and name not in test_df.columns:\n",
    "            return name\n",
    "    raise ValueError(f\"Couldn't detect target. Candidates: {diff}\")\n",
    "\n",
    "# Prefer pre-made splits if available\n",
    "train_path = DATA_DIR / 'train.csv'\n",
    "test_path = DATA_DIR / 'test.csv'\n",
    "train_split_path = SPLITS_DIR / 'train_split.csv'\n",
    "val_split_path = SPLITS_DIR / 'test_split.csv'\n",
    "\n",
    "if train_split_path.exists() and val_split_path.exists():\n",
    "    log('Using precomputed splits from Data/splits')\n",
    "    train_df = pd.read_csv(train_split_path)\n",
    "    val_df = pd.read_csv(val_split_path)\n",
    "    # Reconstruct combined train for full fit later (if train.csv also exists)\n",
    "    if train_path.exists():\n",
    "        full_train_df = pd.read_csv(train_path)\n",
    "    else:\n",
    "        full_train_df = pd.concat([train_df, val_df], axis=0, ignore_index=True)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    target_col = 'loan_paid_back' if 'loan_paid_back' in train_df.columns else detect_target(train_df, test_df)\n",
    "else:\n",
    "    log('Loading Data/train.csv and Data/test.csv; creating a stratified hold-out split (80/20)')\n",
    "    train_full = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    target_col = detect_target(train_full, test_df)\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_full, test_size=0.2, stratify=train_full[target_col], random_state=SEED\n",
    "    )\n",
    "    full_train_df = train_full\n",
    "\n",
    "id_col = 'id' if 'id' in train_df.columns else None\n",
    "log(f\"Detected target: {target_col} | id: {id_col}\")\n",
    "\n",
    "# Basic profiling\n",
    "def profile(df: pd.DataFrame, name: str):\n",
    "    print(f\"\\n=== {name} ({df.shape[0]} rows, {df.shape[1]} columns) ===\")\n",
    "    print(\"Head:\\n\", df.head(3))\n",
    "    print(\"Nulls:\\n\", df.isnull().mean().sort_values(ascending=False).head(10))\n",
    "    print(\"Dtypes:\\n\", df.dtypes.value_counts())\n",
    "\n",
    "profile(train_df, 'Train')\n",
    "profile(val_df, 'Validation')\n",
    "profile(test_df, 'Test')\n",
    "\n",
    "# Class balance\n",
    "print(\"\\nClass balance (train):\")\n",
    "print(train_df[target_col].value_counts(normalize=True).rename('share'))\n",
    "\n",
    "# Separate X/y\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "X_val = val_df.drop(columns=[target_col])\n",
    "y_val = val_df[target_col]\n",
    "\n",
    "categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "log(f\"Numeric: {len(numeric_cols)} | Categorical: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb6ba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Train df: shape=(475195, 13)\n",
      "       id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  100143       92432.16                 0.067           636     14369.05   \n",
      "1  560097       28850.38                 0.122           643      8471.26   \n",
      "2  356847       39427.43                 0.041           672      7647.50   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          13.78    Male        Married      Bachelor's          Employed   \n",
      "1          14.40  Female        Married     High School          Employed   \n",
      "2          11.99    Male        Married     High School          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  loan_paid_back  \n",
      "0  Debt consolidation             D1             1.0  \n",
      "1  Debt consolidation             D5             1.0  \n",
      "2  Debt consolidation             C3             1.0  \n",
      "[DEBUG] top-10 null ratios:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "\n",
      "[DEBUG] Validation df: shape=(118799, 13)\n",
      "       id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  523771       28114.66                 0.080           690      7133.85   \n",
      "1  524810      122933.72                 0.046           659      7268.12   \n",
      "2  100141       26379.82                 0.140           710      9386.27   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          11.80  Female        Married     High School          Employed   \n",
      "1           7.46    Male         Single     High School          Employed   \n",
      "2          12.73    Male        Married      Bachelor's          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  loan_paid_back  \n",
      "0                 Car             C1             1.0  \n",
      "1                Home             D5             1.0  \n",
      "2  Debt consolidation             C2             1.0  \n",
      "[DEBUG] top-10 null ratios:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "\n",
      "[DEBUG] Test df: shape=(254569, 12)\n",
      "       id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  593994       28781.05                 0.049           626     11461.42   \n",
      "1  593995       46626.39                 0.093           732     15492.25   \n",
      "2  593996       54954.89                 0.367           611      3796.41   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          14.73  Female         Single     High School          Employed   \n",
      "1          12.85  Female        Married        Master's          Employed   \n",
      "2          13.29    Male         Single      Bachelor's          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  \n",
      "0               Other             D5  \n",
      "1               Other             C1  \n",
      "2  Debt consolidation             D1  \n",
      "[DEBUG] top-10 null ratios:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "[DEBUG 20:57:54] Target detected: loan_paid_back | In test? False\n",
      "[DEBUG 20:57:54] ID column: id\n",
      "[DEBUG 20:57:54] Numeric cols: 6 | Categorical cols: 6\n",
      "[DEBUG] top-10 null ratios:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "\n",
      "[DEBUG] Validation df: shape=(118799, 13)\n",
      "       id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  523771       28114.66                 0.080           690      7133.85   \n",
      "1  524810      122933.72                 0.046           659      7268.12   \n",
      "2  100141       26379.82                 0.140           710      9386.27   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          11.80  Female        Married     High School          Employed   \n",
      "1           7.46    Male         Single     High School          Employed   \n",
      "2          12.73    Male        Married      Bachelor's          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  loan_paid_back  \n",
      "0                 Car             C1             1.0  \n",
      "1                Home             D5             1.0  \n",
      "2  Debt consolidation             C2             1.0  \n",
      "[DEBUG] top-10 null ratios:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "\n",
      "[DEBUG] Test df: shape=(254569, 12)\n",
      "       id  annual_income  debt_to_income_ratio  credit_score  loan_amount  \\\n",
      "0  593994       28781.05                 0.049           626     11461.42   \n",
      "1  593995       46626.39                 0.093           732     15492.25   \n",
      "2  593996       54954.89                 0.367           611      3796.41   \n",
      "\n",
      "   interest_rate  gender marital_status education_level employment_status  \\\n",
      "0          14.73  Female         Single     High School          Employed   \n",
      "1          12.85  Female        Married        Master's          Employed   \n",
      "2          13.29    Male         Single      Bachelor's          Employed   \n",
      "\n",
      "         loan_purpose grade_subgrade  \n",
      "0               Other             D5  \n",
      "1               Other             C1  \n",
      "2  Debt consolidation             D1  \n",
      "[DEBUG] top-10 null ratios:\n",
      " id                      0.0\n",
      "annual_income           0.0\n",
      "debt_to_income_ratio    0.0\n",
      "credit_score            0.0\n",
      "loan_amount             0.0\n",
      "interest_rate           0.0\n",
      "gender                  0.0\n",
      "marital_status          0.0\n",
      "education_level         0.0\n",
      "employment_status       0.0\n",
      "dtype: float64\n",
      "[DEBUG 20:57:54] Target detected: loan_paid_back | In test? False\n",
      "[DEBUG 20:57:54] ID column: id\n",
      "[DEBUG 20:57:54] Numeric cols: 6 | Categorical cols: 6\n"
     ]
    }
   ],
   "source": [
    "# === Debug: Data overview checks ===\n",
    "try:\n",
    "    trace_df(train_df, 'Train df')\n",
    "    trace_df(val_df, 'Validation df')\n",
    "    trace_df(test_df, 'Test df')\n",
    "    log_debug(f\"Target detected: {target_col} | In test? {target_col in test_df.columns}\")\n",
    "    assert target_col not in test_df.columns, \"Data leakage: target present in test set!\"\n",
    "    log_debug(f\"ID column: {id_col}\")\n",
    "    log_debug(f\"Numeric cols: {len(numeric_cols)} | Categorical cols: {len(categorical_cols)}\")\n",
    "except Exception as e:\n",
    "    print(\"[DEBUG ERROR] Data overview checks failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51142d96",
   "metadata": {},
   "source": [
    "## 3) Ultra-Advanced Feature Engineering v3\n",
    "We create rich interaction features (polynomial on numeric), clustering features, PCA components, and safe domain ratios. This block is leak-safe: fitted only on training data and then applied to validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5a9a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:02:21] Poly shape: (475195, 20), PCA shape: (475195, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Build preprocessing for numeric/categorical\n",
    "num_transform = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='median')),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "cat_transform = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='most_frequent')),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse_output=True)),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", num_transform, numeric_cols),\n",
    "    (\"cat\", cat_transform, categorical_cols),\n",
    "])\n",
    "\n",
    "# Additional engineered numeric features (leak-safe):\n",
    "# - Polynomial interactions on key numeric columns\n",
    "# - KMeans cluster labels on numeric\n",
    "# - PCA components on scaled numeric\n",
    "\n",
    "key_numeric = [c for c in numeric_cols if c not in ([id_col] if id_col else [])]\n",
    "key_numeric = key_numeric[:min(12, len(key_numeric))]  # cap to keep runtime reasonable\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "kmeans = KMeans(n_clusters=min(8, max(2, int(len(X_train)**0.5)//500)), random_state=SEED, n_init='auto')\n",
    "pca = PCA(n_components=min(10, max(2, len(key_numeric))))\n",
    "\n",
    "# Fit on train only\n",
    "Xn_train = X_train[key_numeric].copy()\n",
    "Xn_val = X_val[key_numeric].copy()\n",
    "Xn_test = test_df[key_numeric].copy()\n",
    "\n",
    "imp = SimpleImputer(strategy='median').fit(Xn_train)\n",
    "Xn_train_imputed = imp.transform(Xn_train)\n",
    "Xn_val_imputed = imp.transform(Xn_val)\n",
    "Xn_test_imputed = imp.transform(Xn_test)\n",
    "\n",
    "# Scale numeric for poly/pca consistency\n",
    "scaler_tmp = StandardScaler().fit(Xn_train_imputed)\n",
    "Xn_train_s = scaler_tmp.transform(Xn_train_imputed)\n",
    "Xn_val_s = scaler_tmp.transform(Xn_val_imputed)\n",
    "Xn_test_s = scaler_tmp.transform(Xn_test_imputed)\n",
    "\n",
    "# Polynomial features\n",
    "poly.fit(Xn_train_s)\n",
    "poly_train = poly.transform(Xn_train_s)\n",
    "poly_val = poly.transform(Xn_val_s)\n",
    "poly_test = poly.transform(Xn_test_s)\n",
    "\n",
    "# KMeans clusters\n",
    "kmeans.fit(Xn_train_s)\n",
    "km_train = kmeans.predict(Xn_train_s).reshape(-1, 1)\n",
    "km_val = kmeans.predict(Xn_val_s).reshape(-1, 1)\n",
    "km_test = kmeans.predict(Xn_test_s).reshape(-1, 1)\n",
    "\n",
    "# PCA components\n",
    "pca.fit(Xn_train_s)\n",
    "pca_train = pca.transform(Xn_train_s)\n",
    "pca_val = pca.transform(Xn_val_s)\n",
    "pca_test = pca.transform(Xn_test_s)\n",
    "\n",
    "log(f\"Poly shape: {poly_train.shape}, PCA shape: {pca_train.shape}\")\n",
    "\n",
    "# We'll incorporate these engineered arrays later via model-specific pipelines where useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Debug: Feature engineering artefacts ===\n",
    "try:\n",
    "    trace_array(poly_train, 'poly_train')\n",
    "    trace_array(pca_train, 'pca_train')\n",
    "    if DEBUG:\n",
    "        # KMeans cluster distribution\n",
    "        import numpy as _np\n",
    "        unique, counts = _np.unique(km_train, return_counts=True)\n",
    "        print('[DEBUG] KMeans clusters (train):', dict(zip(unique.tolist(), counts.tolist())))\n",
    "except Exception as e:\n",
    "    print('[DEBUG ERROR] Feature engineering trace failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2ffc1",
   "metadata": {},
   "source": [
    "## 4) Feature Selection and Dimensionality Reduction\n",
    "We combine mutual information filtering with model-based selection (L1/Lasso) and correlation pruning to reduce noise while keeping useful signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1640d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:07] Feature selection kept 61 / 61 features\n"
     ]
    }
   ],
   "source": [
    "# Fit a quick baseline preprocessing to produce a dense numeric matrix for filter methods\n",
    "prep_dense = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy='median'), numeric_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "])\n",
    "Xtrain_dense = prep_dense.fit_transform(X_train)\n",
    "Xval_dense = prep_dense.transform(X_val)\n",
    "\n",
    "# Keep feature names for OHE\n",
    "num_names = numeric_cols\n",
    "cat_names = prep_dense.named_transformers_['cat'].get_feature_names_out(categorical_cols).tolist() if len(categorical_cols) else []\n",
    "all_names = num_names + cat_names\n",
    "\n",
    "# Mutual information selection (top k)\n",
    "mi_scores = mutual_info_classif(Xtrain_dense, y_train, random_state=SEED)\n",
    "mi_k = min(200, Xtrain_dense.shape[1])\n",
    "mi_idx = np.argsort(mi_scores)[-mi_k:]\n",
    "mi_mask = np.zeros(Xtrain_dense.shape[1], dtype=bool)\n",
    "mi_mask[mi_idx] = True\n",
    "\n",
    "# L1 selection via LogisticRegression (saga)\n",
    "l1 = LogisticRegression(penalty='l1', solver='saga', C=0.2, max_iter=2000, n_jobs=None)\n",
    "l1.fit(Xtrain_dense, y_train)\n",
    "l1_mask = np.abs(l1.coef_).ravel() > 1e-6\n",
    "\n",
    "# Combined mask (union)\n",
    "keep_mask = mi_mask | l1_mask\n",
    "Xtrain_sel = Xtrain_dense[:, keep_mask]\n",
    "Xval_sel = Xval_dense[:, keep_mask]\n",
    "sel_names = [n for n, m in zip(all_names, keep_mask) if m]\n",
    "\n",
    "log(f\"Feature selection kept {Xtrain_sel.shape[1]} / {Xtrain_dense.shape[1]} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e8b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Debug: Feature selection details ===\n",
    "try:\n",
    "    if DEBUG:\n",
    "        # Top-20 MI features\n",
    "        topk = np.argsort(mi_scores)[-20:][::-1]\n",
    "        top_pairs = [(all_names[i], float(mi_scores[i])) for i in topk]\n",
    "        print('[DEBUG] Top-20 MI features:')\n",
    "        for name, score in top_pairs:\n",
    "            print(f'  - {name:40s} {score:.5f}')\n",
    "        nonzero_l1 = int(np.sum(l1_mask))\n",
    "        print(f\"[DEBUG] L1 non-zero features: {nonzero_l1}\")\n",
    "        print(f\"[DEBUG] Selected features total: {len(sel_names)}\")\n",
    "except Exception as e:\n",
    "    print('[DEBUG ERROR] Feature selection debug failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb8032",
   "metadata": {},
   "source": [
    "## 5) Hyperparameter Optimization with Optuna (XGBoost, LightGBM, CatBoost)\n",
    "We tune key parameters for tree boosters using 3-fold stratified CV with pruning. Optimizes ROC-AUC primarily and reports accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Import heavy libs on-demand (deferred from first cell)\n",
    "optuna = ensure('optuna')\n",
    "xgb = ensure('xgboost', 'xgboost')\n",
    "lgbm = ensure('lightgbm', 'lightgbm')\n",
    "catboost = ensure('catboost', 'catboost')\n",
    "\n",
    "roc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "# Shared preprocessor for boosters\n",
    "booster_pre = preprocess\n",
    "\n",
    "# Helper: CV evaluation\n",
    "\n",
    "def cv_score_model(model, X, y, cv=3):\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=SEED)\n",
    "    scores = []\n",
    "    for tr_idx, va_idx in skf.split(X, y):\n",
    "        Xtr, Xva = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        ytr, yva = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "        pipe = Pipeline([\n",
    "            (\"prep\", booster_pre),\n",
    "            (\"clf\", model)\n",
    "        ])\n",
    "        pipe.fit(Xtr, ytr)\n",
    "        proba = pipe.predict_proba(Xva)[:, 1]\n",
    "        scores.append(roc_auc_score(yva, proba))\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "# XGBoost optimization\n",
    "\n",
    "def optimize_xgb(trials=30):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 200, 1200),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0.0, 0.5),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'random_state': SEED,\n",
    "            'n_jobs': N_JOBS,\n",
    "            'tree_method': 'hist',\n",
    "        }\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        return cv_score_model(model, X_train, y_train, cv=3)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials, show_progress_bar=False)\n",
    "    log(f\"XGB best AUC: {study.best_value:.4f}\")\n",
    "    return study.best_params\n",
    "\n",
    "# LightGBM optimization\n",
    "\n",
    "def optimize_lgbm(trials=30):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 300, 1500),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 15, 80),\n",
    "            'max_depth': trial.suggest_int('max_depth', -1, 12),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'random_state': SEED,\n",
    "            'n_jobs': N_JOBS,\n",
    "            'verbose': -1,\n",
    "        }\n",
    "        model = lgbm.LGBMClassifier(**params)\n",
    "        return cv_score_model(model, X_train, y_train, cv=3)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials, show_progress_bar=False)\n",
    "    log(f\"LGBM best AUC: {study.best_value:.4f}\")\n",
    "    return study.best_params\n",
    "\n",
    "# CatBoost optimization\n",
    "\n",
    "def optimize_cat(trials=30):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 300, 1500),\n",
    "            'depth': trial.suggest_int('depth', 4, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "            'random_state': SEED,\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'verbose': False,\n",
    "            'auto_class_weights': 'Balanced',\n",
    "        }\n",
    "        model = catboost.CatBoostClassifier(**params)\n",
    "        return cv_score_model(model, X_train, y_train, cv=3)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials, show_progress_bar=False)\n",
    "    log(f\"CatBoost best AUC: {study.best_value:.4f}\")\n",
    "    return study.best_params\n",
    "\n",
    "# Run quick searches (tune trials to your compute budget)\n",
    "xgb_best = optimize_xgb(trials=25)\n",
    "lgbm_best = optimize_lgbm(trials=25)\n",
    "cat_best = optimize_cat(trials=20)\n",
    "\n",
    "log(\"Best params collected for boosters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Debug: Optuna best params summary ===\n",
    "try:\n",
    "    if DEBUG:\n",
    "        import json as _json\n",
    "        print('[DEBUG] XGB best params:\\n', _json.dumps(xgb_best, indent=2))\n",
    "        print('[DEBUG] LGBM best params:\\n', _json.dumps(lgbm_best, indent=2))\n",
    "        print('[DEBUG] CatBoost best params:\\n', _json.dumps(cat_best, indent=2))\n",
    "except Exception as e:\n",
    "    print('[DEBUG ERROR] Optuna debug summary failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dfe6ab",
   "metadata": {},
   "source": [
    "## 7) Adversarial Validation\n",
    "Train a classifier distinguishing train vs test to assess distribution shift. If AUC is high, consider down-weighting or engineering features that cause mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d81979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:19:29] Adversarial AUC (train vs test): 1.0000 ± 0.0000\n",
      "Warning: Significant train-test shift detected. Consider revisiting features/splits.\n"
     ]
    }
   ],
   "source": [
    "# Build dataset for adversarial validation\n",
    "adv_train = full_train_df.drop(columns=[target_col])\n",
    "adv_test = test_df.copy()\n",
    "adv_train['__is_test__'] = 0\n",
    "adv_test['__is_test__'] = 1\n",
    "\n",
    "df_adv = pd.concat([adv_train, adv_test], axis=0, ignore_index=True)\n",
    "\n",
    "X_adv = df_adv.drop(columns=['__is_test__'])\n",
    "y_adv = df_adv['__is_test__']\n",
    "\n",
    "cat_adv = X_adv.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_adv = X_adv.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "adv_prep = ColumnTransformer([\n",
    "    (\"num\", SimpleImputer(strategy='median'), num_adv),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse_output=True), cat_adv),\n",
    "])\n",
    "\n",
    "adv_clf = GradientBoostingClassifier(random_state=SEED)\n",
    "pipe_adv = Pipeline([\n",
    "    (\"prep\", adv_prep),\n",
    "    (\"clf\", adv_clf)\n",
    "])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "adv_scores = cross_val_score(pipe_adv, X_adv, y_adv, cv=skf, scoring='roc_auc')\n",
    "log(f\"Adversarial AUC (train vs test): {adv_scores.mean():.4f} ± {adv_scores.std():.4f}\")\n",
    "\n",
    "if adv_scores.mean() > 0.75:\n",
    "    print(\"Warning: Significant train-test shift detected. Consider revisiting features/splits.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bb46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Debug: Adversarial validation per-fold ===\n",
    "try:\n",
    "    if DEBUG:\n",
    "        print('[DEBUG] Adversarial per-fold AUCs:', adv_scores)\n",
    "except Exception as e:\n",
    "    print('[DEBUG ERROR] Adversarial debug failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c5ce3",
   "metadata": {},
   "source": [
    "## 8) Pseudo-Labeling on High-Confidence Predictions\n",
    "We fit the current best booster, label very confident test examples, and retrain with augmented data to potentially squeeze extra accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an XGB with best parameters and pseudo-label\n",
    "xgb_clf = xgb.XGBClassifier(**{**xgb_best, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'random_state': SEED, 'n_jobs': N_JOBS, 'tree_method': 'hist'})\n",
    "pipe_xgb = Pipeline([('prep', preprocess), ('clf', xgb_clf)])\n",
    "pipe_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test probabilities, select confident samples\n",
    "proba_test = pipe_xgb.predict_proba(test_df)[:, 1]\n",
    "hi_mask = (proba_test >= 0.95) | (proba_test <= 0.05)\n",
    "pseudo_labels = (proba_test[hi_mask] >= 0.5).astype(int)\n",
    "X_pseudo = test_df.loc[hi_mask].copy()\n",
    "\n",
    "log(f\"Pseudo-labeling: selected {hi_mask.sum()} high-confidence test samples\")\n",
    "\n",
    "# Augment training data\n",
    "X_aug = pd.concat([X_train, X_pseudo], axis=0)\n",
    "y_aug = pd.concat([y_train, pd.Series(pseudo_labels, index=X_pseudo.index, name=target_col)], axis=0)\n",
    "\n",
    "# Sample weights to down-weight pseudo labels\n",
    "w = np.ones(len(y_aug))\n",
    "w[-len(pseudo_labels):] = 0.5\n",
    "\n",
    "# Refit XGB on augmented data\n",
    "pipe_xgb.fit(X_aug, y_aug, clf__sample_weight=w)\n",
    "val_proba_xgb = pipe_xgb.predict_proba(X_val)[:, 1]\n",
    "val_acc_xgb = accuracy_score(y_val, (val_proba_xgb >= 0.5).astype(int))\n",
    "val_auc_xgb = roc_auc_score(y_val, val_proba_xgb)\n",
    "log(f\"XGB after pseudo-labeling — Val Acc: {val_acc_xgb:.4f}, ROC-AUC: {val_auc_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171563c",
   "metadata": {},
   "source": [
    "## 9) Deep Stacking with Multiple Levels\n",
    "Build Level-1 OOF predictions from 5 diverse models (XGB, LGBM, CatBoost, RandomForest, HistGB), then train a Level-2 meta-learner. Compare stacking to simple averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oof_predictions(estimator, X, y, X_val, cv=CV_FOLDS, name='model'):\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=SEED)\n",
    "    oof = np.zeros(len(X))\n",
    "    val = np.zeros(len(X_val))\n",
    "    for f, (tr, va) in enumerate(skf.split(X, y), 1):\n",
    "        pipe = Pipeline([\n",
    "            ('prep', preprocess),\n",
    "            ('clf', estimator)\n",
    "        ])\n",
    "        pipe.fit(X.iloc[tr], y.iloc[tr])\n",
    "        oof[va] = pipe.predict_proba(X.iloc[va])[:, 1]\n",
    "        val += pipe.predict_proba(X_val)[:, 1] / cv\n",
    "    auc = roc_auc_score(y, oof)\n",
    "    log(f\"{name} OOF AUC: {auc:.4f}\")\n",
    "    return oof, val\n",
    "\n",
    "# Base estimators with tuned params\n",
    "xgb_base = xgb.XGBClassifier(**{**xgb_best, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'random_state': SEED, 'n_jobs': N_JOBS, 'tree_method': 'hist'})\n",
    "lgbm_base = lgbm.LGBMClassifier(**{**lgbm_best, 'objective': 'binary', 'random_state': SEED, 'n_jobs': N_JOBS})\n",
    "cat_base = catboost.CatBoostClassifier(**{**cat_best, 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'random_state': SEED, 'verbose': False})\n",
    "rf_base = RandomForestClassifier(n_estimators=400, max_depth=None, min_samples_split=4, class_weight='balanced_subsample', n_jobs=N_JOBS, random_state=SEED)\n",
    "hgb_base = HistGradientBoostingClassifier(max_iter=400, learning_rate=0.05, max_depth=None, random_state=SEED)\n",
    "\n",
    "# Compute OOF for 5 classical models\n",
    "oof_xgb, val_xgb = oof_predictions(xgb_base, X_train, y_train, X_val, name='XGB')\n",
    "oof_lgb, val_lgb = oof_predictions(lgbm_base, X_train, y_train, X_val, name='LGBM')\n",
    "oof_cat, val_cat = oof_predictions(cat_base, X_train, y_train, X_val, name='CatBoost')\n",
    "oof_rf, val_rf = oof_predictions(rf_base, X_train, y_train, X_val, name='RandomForest')\n",
    "oof_hgb, val_hgb = oof_predictions(hgb_base, X_train, y_train, X_val, name='HistGB')\n",
    "\n",
    "# Level-1 meta features\n",
    "M_train = np.column_stack([oof_xgb, oof_lgb, oof_cat, oof_rf, oof_hgb])\n",
    "M_val = np.column_stack([val_xgb, val_lgb, val_cat, val_rf, val_hgb])\n",
    "\n",
    "# Meta-learner\n",
    "meta_lr = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "meta_lr.fit(M_train, y_train)\n",
    "val_meta_lr = meta_lr.predict_proba(M_val)[:, 1]\n",
    "\n",
    "meta_auc = roc_auc_score(y_val, val_meta_lr)\n",
    "meta_acc = accuracy_score(y_val, (val_meta_lr >= 0.5).astype(int))\n",
    "log(f\"Level-2 Meta (LR) — Val Acc: {meta_acc:.4f}, ROC-AUC: {meta_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Debug: Stacking matrices ===\n",
    "try:\n",
    "    if DEBUG:\n",
    "        print('[DEBUG] M_train shape:', M_train.shape)\n",
    "        print('[DEBUG] M_val shape:', M_val.shape)\n",
    "        print('[DEBUG] First row M_train:', M_train[0, :])\n",
    "except Exception as e:\n",
    "    print('[DEBUG ERROR] Stacking debug failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06a2e7",
   "metadata": {},
   "source": [
    "## 10) Prediction Calibration and Threshold Optimization\n",
    "We calibrate probabilities (isotonic and Platt) and search for the threshold that maximizes validation accuracy (and report Youden's J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# Use meta probabilities (val_meta_lr) for calibration comparison\n",
    "proba_uncal = val_meta_lr\n",
    "\n",
    "# Platt scaling via CalibratedClassifierCV requires a classifier; simulate by refitting on full M_train\n",
    "meta_lr_full = LogisticRegression(max_iter=2000, class_weight='balanced').fit(M_train, y_train)\n",
    "cal_platt = CalibratedClassifierCV(meta_lr_full, method='sigmoid', cv=3)\n",
    "cal_platt.fit(M_train, y_train)\n",
    "proba_platt = cal_platt.predict_proba(M_val)[:, 1]\n",
    "\n",
    "# Isotonic on meta outputs\n",
    "iso = IsotonicRegression(out_of_bounds='clip')\n",
    "iso.fit(proba_uncal, y_val)\n",
    "proba_iso = iso.predict(proba_uncal)\n",
    "\n",
    "# Threshold search utilities\n",
    "\n",
    "def best_threshold(y_true, proba):\n",
    "    thresholds = np.linspace(0.2, 0.8, 121)\n",
    "    accs, youdens = [], []\n",
    "    fprs, tprs, _ = roc_curve(y_true, proba)\n",
    "    for t in thresholds:\n",
    "        pred = (proba >= t).astype(int)\n",
    "        accs.append(accuracy_score(y_true, pred))\n",
    "        # Youden J approximation at t using confusion\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()\n",
    "        sens = tp / (tp + fn + 1e-9)\n",
    "        spec = tn / (tn + fp + 1e-9)\n",
    "        youdens.append(sens + spec - 1)\n",
    "    ai = int(np.argmax(accs))\n",
    "    yi = int(np.argmax(youdens))\n",
    "    return thresholds[ai], accs[ai], thresholds[yi], youdens[yi]\n",
    "\n",
    "thr_uncal_acc, acc_uncal, thr_uncal_yj, yj_uncal = best_threshold(y_val, proba_uncal)\n",
    "thr_platt_acc, acc_platt, thr_platt_yj, yj_platt = best_threshold(y_val, proba_platt)\n",
    "thr_iso_acc, acc_iso, thr_iso_yj, yj_iso = best_threshold(y_val, proba_iso)\n",
    "\n",
    "log(f\"Meta(LR) thresholds — Uncal: acc@{thr_uncal_acc:.3f}={acc_uncal:.4f} | Platt: acc@{thr_platt_acc:.3f}={acc_platt:.4f} | Iso: acc@{thr_iso_acc:.3f}={acc_iso:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c92c6",
   "metadata": {},
   "source": [
    "## 11) Final Model Selection and Submission Generation\n",
    "We compare calibration strategies, choose the best, train on all data, and generate probability predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4922bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best calibrated variant by validation accuracy\n",
    "variants = [\n",
    "    (\"uncal\", proba_uncal, thr_uncal_acc, acc_uncal),\n",
    "    (\"platt\", proba_platt, thr_platt_acc, acc_platt),\n",
    "    (\"isotonic\", proba_iso, thr_iso_acc, acc_iso)\n",
    "]\n",
    "variants.sort(key=lambda x: x[3], reverse=True)\n",
    "best_name, best_proba_val, best_thr, best_acc = variants[0]\n",
    "log(f\"Chosen calibration: {best_name} | acc@thr={best_acc:.4f} @ {best_thr:.3f}\")\n",
    "\n",
    "# Refit base estimators on FULL train and build M_test\n",
    "base_full_pipes = []\n",
    "base_defs = [\n",
    "    (\"XGB\", xgb_base),\n",
    "    (\"LGBM\", lgbm_base),\n",
    "    (\"Cat\", cat_base),\n",
    "    (\"RF\", rf_base),\n",
    "    (\"HGB\", hgb_base),\n",
    "]\n",
    "M_test_list = []\n",
    "for name, est in base_defs:\n",
    "    log(f\"Fitting base {name} on full train...\")\n",
    "    pipe = Pipeline([('prep', preprocess), ('clf', est)])\n",
    "    pipe.fit(full_train_df.drop(columns=[target_col]), full_train_df[target_col])\n",
    "    proba_test_base = pipe.predict_proba(test_df)[:, 1]\n",
    "    M_test_list.append(proba_test_base)\n",
    "    base_full_pipes.append((name, pipe))\n",
    "\n",
    "# Build M_test from base models only\n",
    "M_test = np.column_stack(M_test_list)\n",
    "\n",
    "# Meta on FULL training\n",
    "meta_full = LogisticRegression(max_iter=2000, class_weight='balanced').fit(M_train, y_train)\n",
    "proba_test_meta_uncal = meta_full.predict_proba(M_test)[:, 1]\n",
    "\n",
    "if best_name == 'platt':\n",
    "    proba_test_final = cal_platt.predict_proba(M_test)[:, 1]\n",
    "elif best_name == 'isotonic':\n",
    "    # Use isotonic fitted on validation meta outputs\n",
    "    proba_test_final = iso.predict(proba_test_meta_uncal)\n",
    "else:\n",
    "    proba_test_final = proba_test_meta_uncal\n",
    "\n",
    "# Save probability submission\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "sub = pd.DataFrame({\n",
    "    id_col if id_col else 'id': test_df[id_col] if id_col else np.arange(len(test_df)),\n",
    "    target_col: proba_test_final\n",
    "})\n",
    "prob_fname = SUB_DIR / f\"{SAVE_PREFIX}_{best_name}_PROBA_{timestamp}.csv\"\n",
    "sub.to_csv(prob_fname, index=False)\n",
    "sub.to_csv(ROOT / 'submission.csv', index=False)\n",
    "log(f\"Saved probability submission: {prob_fname}\")\n",
    "\n",
    "# Also save thresholded labels for local sanity (not for submission)\n",
    "labels = (proba_test_final >= best_thr).astype(int)\n",
    "label_fname = SUB_DIR / f\"{SAVE_PREFIX}_{best_name}_LABELS_{timestamp}.csv\"\n",
    "pd.DataFrame({id_col if id_col else 'id': sub.iloc[:,0], target_col: labels}).to_csv(label_fname, index=False)\n",
    "log(f\"Saved label snapshot: {label_fname}\")\n",
    "\n",
    "# Persist artifacts\n",
    "model_dir = MODELS_DIR / f\"stack_v3__{timestamp}\"\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save meta and calibration\n",
    "dump(meta_full, model_dir / 'meta_lr.joblib')\n",
    "dump(iso, model_dir / 'isotonic.joblib')\n",
    "for name, pipe in base_full_pipes:\n",
    "    dump(pipe, model_dir / f\"base_{name.lower()}.joblib\")\n",
    "\n",
    "with open(model_dir / 'columns.json', 'w') as f:\n",
    "    import json\n",
    "    json.dump({\n",
    "        'numeric': numeric_cols,\n",
    "        'categorical': categorical_cols,\n",
    "        'target': target_col,\n",
    "        'id': id_col,\n",
    "        'selected_dense_features': sel_names,\n",
    "        'version': 'stack_v3-no-nn'\n",
    "    }, f, indent=2)\n",
    "\n",
    "log(f\"Artifacts saved to {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbdc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Debug: Submission artifacts verification ===\n",
    "try:\n",
    "    if DEBUG:\n",
    "        import os\n",
    "        print('[DEBUG] submission.csv exists?', os.path.exists(ROOT / 'submission.csv'))\n",
    "        if os.path.exists(ROOT / 'submission.csv'):\n",
    "            print('[DEBUG] submission.csv size (KB):', round(os.path.getsize(ROOT / 'submission.csv')/1024,2))\n",
    "        # List last 5 files in submissions\n",
    "        from glob import glob\n",
    "        files = sorted(glob(str(SUB_DIR / '*.csv')))\n",
    "        print('[DEBUG] Submissions count:', len(files))\n",
    "        for f in files[-5:]:\n",
    "            print('   -', os.path.basename(f))\n",
    "except Exception as e:\n",
    "    print('[DEBUG ERROR] Submission verification failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3a3c3",
   "metadata": {},
   "source": [
    "## 12) Performance Analysis and Model Persistence\n",
    "We compile validation metrics, plot calibration curves, confusion matrix, and record execution time and saved artifacts for traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ee813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation summary for chosen calibration\n",
    "chosen_proba = {'uncal': proba_uncal, 'platt': proba_platt, 'isotonic': proba_iso}[best_name]\n",
    "val_pred = (chosen_proba >= best_thr).astype(int)\n",
    "\n",
    "print(\"Validation Metrics (chosen calibration):\")\n",
    "print(f\"  Accuracy : {accuracy_score(y_val, val_pred):.4f}\")\n",
    "print(f\"  ROC-AUC  : {roc_auc_score(y_val, chosen_proba):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_val, val_pred):.4f}\")\n",
    "print(f\"  Recall   : {recall_score(y_val, val_pred):.4f}\")\n",
    "print(f\"  F1       : {f1_score(y_val, val_pred):.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_val, val_pred)\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_title('Validation Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calibration curves\n",
    "from sklearn.calibration import calibration_curve\n",
    "for name, proba in [('uncal', proba_uncal), ('platt', proba_platt), ('isotonic', proba_iso)]:\n",
    "    frac_pos, mean_pred = calibration_curve(y_val, proba, n_bins=10)\n",
    "    plt.plot(mean_pred, frac_pos, marker='o', label=name)\n",
    "plt.plot([0,1], [0,1], '--', color='gray')\n",
    "plt.legend()\n",
    "plt.title('Calibration Curves (Validation)')\n",
    "plt.xlabel('Mean predicted value')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.show()\n",
    "\n",
    "# Time summary\n",
    "elapsed = time.time() - start_ts\n",
    "print(f\"\\nTotal elapsed: {int(elapsed//60)}m {int(elapsed%60)}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
